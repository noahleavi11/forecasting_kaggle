{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays \n",
    "from datetime import datetime, date\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this code is to predict a sales for different items over the period of 90-days. It coincides with the kaggle competition found at https://www.kaggle.com/c/demand-forecasting-kernels-only. I chose to use a Neural net for this project. I was interested to see how it would perform compared to other projects that used ARIMA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#used for kernel that was uploaded to Kaggle\n",
    "#train = pd.read_csv('../input/train.csv')\n",
    "#test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  store  item  sales\n",
       "0  2013-01-01      1     1     13\n",
       "1  2013-01-02      1     1     11\n",
       "2  2013-01-03      1     1     14\n",
       "3  2013-01-04      1     1     13\n",
       "4  2013-01-05      1     1     10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>913000.000000</td>\n",
       "      <td>913000.000000</td>\n",
       "      <td>913000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>52.250287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872283</td>\n",
       "      <td>14.430878</td>\n",
       "      <td>28.801144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>231.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               store           item          sales\n",
       "count  913000.000000  913000.000000  913000.000000\n",
       "mean        5.500000      25.500000      52.250287\n",
       "std         2.872283      14.430878      28.801144\n",
       "min         1.000000       1.000000       0.000000\n",
       "25%         3.000000      13.000000      30.000000\n",
       "50%         5.500000      25.500000      47.000000\n",
       "75%         8.000000      38.000000      70.000000\n",
       "max        10.000000      50.000000     231.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 913000 entries, 0 to 912999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   date    913000 non-null  object\n",
      " 1   store   913000 non-null  int64 \n",
      " 2   item    913000 non-null  int64 \n",
      " 3   sales   913000 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 27.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a useful neural network, I extracted important information from the date column. I feature engineered columns that deal with day of the week, day in the year, whether a particular day was a holiday or not, and other features. Most features I transformed to be on a scaled from 1 to -1 by putting them through a cosine function. This gave my features a cyclical pattern that would repeat year over year. I felt like this would help my neural net take into account the cyclical nature of sales year to year and month to month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodeldataframe(mydf):\n",
    "    mydf[\"date\"] = pd.to_datetime(mydf.date)\n",
    "    mydf['dayofweek'] = mydf['date'].apply(lambda x:np.cos((2*np.pi*(x.weekday())/7)-.4))\n",
    "    mydf['month'] = mydf['date'].apply(lambda x: np.cos((2*np.pi*x.month/12)-.1))\n",
    "    mydf['dayinmonth'] = mydf['date'].apply(lambda x: np.cos((2*np.pi*x.day/30)-.1))\n",
    "    mydf['dayinyear'] = mydf['date'].apply(lambda x: np.cos((2*np.pi*x.timetuple().tm_yday/365)-.01))\n",
    "    mydf['year'] = mydf['date'].apply(lambda x: x.year)\n",
    "    usholidays = holidays.US()\n",
    "    mydf['US_holiday'] = mydf['date'].apply(lambda x: x in usholidays).astype(int)\n",
    "    ohe = OneHotEncoder()\n",
    "    df3 = pd.DataFrame(ohe.fit_transform(mydf[[\"store\",\"item\"]]).toarray())\n",
    "    lastforecast=pd.concat([mydf,df3],axis=1)\n",
    "    cleanforecast = lastforecast.drop(['date','store','item'], axis=1)\n",
    "    return cleanforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanforecast = createmodeldataframe(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cleanforecast.drop('sales', axis=1)\n",
    "y_train = cleanforecast['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(66,activation='relu'))\n",
    "model.add(Dense(40,activation='relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(15,activation='relu'))\n",
    "model.add(Dense(15,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 222.0649\n",
      "Epoch 2/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 115.2672\n",
      "Epoch 3/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 106.8861\n",
      "Epoch 4/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 99.6653\n",
      "Epoch 5/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 92.7378\n",
      "Epoch 6/60\n",
      "3567/3567 [==============================] - 6s 2ms/step - loss: 88.8653\n",
      "Epoch 7/60\n",
      "3567/3567 [==============================] - 6s 2ms/step - loss: 85.6216\n",
      "Epoch 8/60\n",
      "3567/3567 [==============================] - 6s 2ms/step - loss: 82.7101\n",
      "Epoch 9/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 81.1810\n",
      "Epoch 10/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 79.1760\n",
      "Epoch 11/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 77.2783\n",
      "Epoch 12/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 75.4900\n",
      "Epoch 13/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 74.3215\n",
      "Epoch 14/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 73.4425\n",
      "Epoch 15/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 72.7699\n",
      "Epoch 16/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 71.8817\n",
      "Epoch 17/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 71.4092\n",
      "Epoch 18/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 70.6595\n",
      "Epoch 19/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 70.1493\n",
      "Epoch 20/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 69.6512\n",
      "Epoch 21/60\n",
      "3567/3567 [==============================] - 8s 2ms/step - loss: 69.2374\n",
      "Epoch 22/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 68.6529\n",
      "Epoch 23/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 68.1093\n",
      "Epoch 24/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 67.6707\n",
      "Epoch 25/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 67.3141\n",
      "Epoch 26/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 67.1702\n",
      "Epoch 27/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 66.8785\n",
      "Epoch 28/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 66.8023\n",
      "Epoch 29/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 66.6456\n",
      "Epoch 30/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 66.5655\n",
      "Epoch 31/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 66.2632\n",
      "Epoch 32/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 66.3888\n",
      "Epoch 33/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 66.1071\n",
      "Epoch 34/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 65.8546\n",
      "Epoch 35/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 65.8266\n",
      "Epoch 36/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 65.6290\n",
      "Epoch 37/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 65.5027\n",
      "Epoch 38/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 65.5596\n",
      "Epoch 39/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 65.3114\n",
      "Epoch 40/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 65.2128\n",
      "Epoch 41/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 64.9717\n",
      "Epoch 42/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 64.9911\n",
      "Epoch 43/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 64.8167\n",
      "Epoch 44/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 64.6304\n",
      "Epoch 45/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 64.0954\n",
      "Epoch 46/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 63.5470\n",
      "Epoch 47/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 63.2013\n",
      "Epoch 48/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 63.0443\n",
      "Epoch 49/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.9572\n",
      "Epoch 50/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.9153\n",
      "Epoch 51/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.7057\n",
      "Epoch 52/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.7980\n",
      "Epoch 53/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.4872\n",
      "Epoch 54/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.5511\n",
      "Epoch 55/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.4116\n",
      "Epoch 56/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.3502\n",
      "Epoch 57/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.3373\n",
      "Epoch 58/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.2662\n",
      "Epoch 59/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.1250\n",
      "Epoch 60/60\n",
      "3567/3567 [==============================] - 7s 2ms/step - loss: 62.1276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2453c4ca040>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train.values,\n",
    "          batch_size=256,epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv(\"test.csv\")\n",
    "testdata = createmodeldataframe(testdf)\n",
    "testids = testdata.id\n",
    "testdata.drop('id',axis=1, inplace=True)\n",
    "testdata = scaler.transform(testdata)\n",
    "testpreds = model.predict(testdata)\n",
    "\n",
    "# added a slight change to predictions to get better results. After looking at a graph of \n",
    "# predicted vs actual_preds on some of my first attempts at this NN, seemed like a transformation\n",
    "# would allow predictions to more closely align with actual results seen\n",
    "testpreds = testpreds**1.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "sub = pd.DataFrame({'id':testids,'sales':testpreds})\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
